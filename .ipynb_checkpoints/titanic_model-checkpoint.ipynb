{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset Analysis with Random Forest Classifier\n",
    "\n",
    "The titanic data set is separated into a training set and a test set. The training set is used here to build a random forest classifier model and test set is used to measure model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ```.csv``` file contains missing values for different features. For example, some entries lack an 'Age' feature. Thus, they have to be filled in accordingly. For numerical features, we fill in with the mean of that feature. For categorical features, we just use the most frequent value for filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_fill(features, X):\n",
    "    for fname in features:\n",
    "        if X[fname].isna().any():\n",
    "            if X[fname].dtype == 'int64' or X[fname].dtype == 'float64':\n",
    "                X[fname].fillna(X[fname].mean(), inplace=True)\n",
    "            elif X[fname].dtype == 'object':\n",
    "                X[fname].fillna(X[fname].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv('train.csv')\n",
    "X_test_full = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the target from the predictors and drop features that are bad predictors such as name, ticket, and cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_full['Survived']\n",
    "X_full.drop(['Survived'], axis=1, inplace=True)\n",
    "X_full.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "#For all features that have missing values, fill them in accordingly\n",
    "features = ['Pclass', 'Sex', 'Embarked', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "missing_values_fill(features, X_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the training and test data with an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = X_train_full[features].copy()\n",
    "X_valid = X_valid_full[features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables must have a numerical representation in order to be used in the model. Such features are one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [fname for fname in X_full.columns\n",
    "                        if X_full[fname].dtype == 'object']\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_X_train = pd.DataFrame(OH_encoder.fit_transform(X_train[categorical_features]))\n",
    "OH_X_valid = pd.DataFrame(OH_encoder.transform(X_valid[categorical_features]))\n",
    "\n",
    "OH_X_train.index = X_train.index\n",
    "OH_X_valid.index = X_valid.index\n",
    "\n",
    "numerical_X_train = X_train.drop(categorical_features, axis=1)\n",
    "numerical_X_valid = X_valid.drop(categorical_features, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([numerical_X_train, OH_X_train], axis=1)\n",
    "OH_X_valid = pd.concat([numerical_X_valid, OH_X_valid], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify our model: ```RandomForestClassifier``` with 100 decision trees and fit the training data. We measure the quality of our model using the model ```score```. It has about 86% accuracy, which is fairly accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603351955307262\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "rf_model.fit(OH_X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(OH_X_valid)\n",
    "print(rf_model.score(OH_X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally predict with the test data and save our predictions to ```submission.csv```. Just as before, the data must be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features that can't predict anything\n",
    "X_test_full.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "#Fill missing values\n",
    "missing_values_fill(features, X_test_full)\n",
    "X_test = X_test_full[features].copy()\n",
    "\n",
    "#One-hot encode categorical features\n",
    "OH_X_test = pd.DataFrame(OH_encoder.fit_transform(X_test[categorical_features]))\n",
    "OH_X_test.index = X_test.index\n",
    "numerical_X_test = X_test.drop(categorical_features, axis=1)\n",
    "OH_X_test = pd.concat([numerical_X_test, OH_X_test], axis=1)\n",
    "\n",
    "#Make predictions\n",
    "test_predictions = rf_model.predict(OH_X_test)\n",
    "output = pd.DataFrame({'PassengerId': X_test_full.PassengerId,\n",
    "                       'Survived': test_predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This model scored about 77% accuracy in the Kaggle competition which is about 65th percentile (a fair/passable score). To improve this model, techniques such as feature engineering must be implemented."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
